# -*- coding: utf-8 -*-
"""Car_Brand_Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xdxMCAz4FVfk_5P-1WVOWRm1yt51K08Z
"""

from zipfile import ZipFile
file_name = 'Datasets.zip'

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print("Done")

!rm -rf Datasets.zip

from tensorflow.keras.layers import Input,Lambda,Dense,Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.resnet50 import ResNet50

from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob
import matplotlib.pyplot as plt

#re-size all the images to this
IMAGE_SIZE = [224,224]

train_path = 'Datasets/train'
test_path = 'Datasets/test'

#importing resnet 50 lib and removing last layer of softmax
#here we also adding weight of imagenet

resnet = ResNet50(input_shape = IMAGE_SIZE + [3],weights = 'imagenet',include_top=False)

resnet.summary()

#don't train existing weights,beacaus we just need to train last layer only
for layer in resnet.layers:
    layer.trainable = False

#usefull to get number of classes

folders = glob('Datasets/Train/*')

folders

#our last layer
x = Flatten()(resnet.output)

prediction = Dense(len(folders),activation='softmax')(x)

#created a model object
model = Model(inputs = resnet.input,outputs=prediction)

model.summary()

model.compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = ['accuracy']
)

train_datagen = ImageDataGenerator(rescale = 1.0/255,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1.0/255)

#provide target same as that of cnn input
train_set = train_datagen.flow_from_directory("Datasets/Train",
                                             target_size = (224,224),
                                             batch_size = 30,
                                             class_mode = 'categorical')

#provide target same as that of cnn input
test_set = test_datagen.flow_from_directory("Datasets/Test",
                                             target_size = (224,224),
                                             batch_size = 30,
                                             class_mode = 'categorical')

r = model.fit_generator(
            train_set,
            validation_data = test_set,
            epochs = 50,
            steps_per_epoch=len(train_set),
            validation_steps = len(test_set))

r.history

#plot loss
plt.plot(r.history['loss'],label = 'train loss')
plt.plot(r.history['val_loss'],label = 'val loss')
plt.legend()
plt.show()
plt.savefig('loss')

#plot accuracy
plt.plot(r.history['accuracy'],label = 'train accuracy')
plt.plot(r.history['val_accuracy'],label = 'val accuracy')
plt.legend()
plt.show()
plt.savefig('accuracy')

from tensorflow.keras.models import load_model

model.save('model_resnet50')

y_predict = model.predict(test_set)

import numpy as np
y_prdict = np.argmax(y_predict)
y_prdict

img = image.load_img('Datasets/Test/lamborghini/10.jpg',target_size=(224,224))

x = image.img_to_array(img)
x.shape
x = x/255

model = load_model('model_resnet50')

x = np.expand_dims(x,axis=0)
img_data = preprocess_input(x)
img_data.shape

a = np.argmax(model.predict(img_data),axis=1)
a

!zip -r /content/model_resnet50.zip  /content/model_resnet50

from google.colab import files
files.download('model_resnet50.zip')